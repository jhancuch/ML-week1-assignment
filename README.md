# EDA for Kaggle Housing Prices Dataset

## Intro
The purpose of this repository is to conduct exploritory data analysis (EDA) on the "Housing Prices - Advanced Regression Techniques" dataset found on kaggle ([dataset link](httpswww.sec.govfilesforms-3-4-5.pdf)). The following paragraphs covers analysis and insights generated by examining:
* Distribution of the dependent variable
* Missing data and outliers
* Potential predictors of the dependent variable
* Feature creation by splitting, merging, or otherwise generating a new predictor
* Min-max and standard scaling including the dependent variable

## Distribution of the dependent variable
First, using a histogram of the dependent variable values to visually represent the distribution, we can see SalePrice has a long right-hand tail. This means the variable has a positive skew and we see this in the statistic computed with the value of 1.88. We can also note the skewness from the difference between the mean and median. The mean can be heavily influenced by outliers and we see that the mean SalePrice is $180,921 while the median is $163,000 indicating outliers on the right-hand of the distribution. 
In Ames, Iowa, it appears that the median house for $163,000 but the top 25% of sales sell for $214,000 or higher with a max of $755,000. With a standard deviation of $79,442, the top quartile contains observations outside of the 3 standard deviation rule indicating we may have outliers. 

## Missing data and outliers
### Missing data
I first find the number of observations (1,460 in this case) and then determine which independent variables are missing values. There are 19 independent variables missing data with the total amount missing ranging from 1 to 1,453. Examining the number of missing values for each observation, I find 87% of the observations are missing 3 to 5 values. The most likely culprits are the variables Alley, FireplaceQu, PoolQC, Fence, and MiscFeature. Depending on what the value optons are for these categorical variables or if there is a related variable, the missing values may be able to be recoded as does not exist rather than dropping observations or these variables. For example, there are only 7 non-null values for PoolQC. However, we don't have any missing values for PoolArea and this variable includes a 0 value as an option. Thus, using PoolArea, we may be able to impute the 1,453 missing values for PoolQC.

By plotting histograms of the 19 independent variables with missing data, we can see that for categorical variables, there appears that most of the variables don't have an None, or Not Applicable option. Further work is needed but there is a potential that most of these missing values can be recoded as a None or Not Applicable value.

### Outliers
To examine outliers, I take three steps. First, for variables with numerical values, I generate box plots to get a sense of the distribution and subsequent outliers. Most independent variables have at least a couple outliers. For variables where zero is a valid value, we see more outliers due to the number of zeros pulling down the median. Good examples of this phenomonin are BsmtFinSF1 and WoodDeckSF. If the house does not have a basement or wood deck, they have a value of 0 which effects the boxplots since we are taking into account observations that don't have a basement or wood deck. 

Second, for categorical variables, I generate histograms to get a sense of the number of possible values each categorical variable can take on and the distribution of the values. The results are mixed, with some variables having majority of one value (ExterCond, BldgType, Heating, CentralAir), others having the distribution of the left side of a normal distribution (HeatingQC, Neighborhood, HousingStyle), and others having an even distribution (PoolQC, GarageFinish, Alley). 

Third, I generate scatter plots with the independent variables on the x axis and the dependent variable (SalePrice) on the y axis. Since SalePrice is the variable of interest, these scatter plots show us the relationship between SalePrice and the independent variables and if there are any outliers that would effect a fitted model. Outliers effect the fitted regression line with the weight of the effect of outliers varying by what type of model/regression is used. Examining the resulting scatter plots, we can see that most of the continious variables have outliers that will need to be examined further when devloping the model. We can see that across similar variables (GrLivArea, 1stFlrSF, BsmFinSF1) there are similar placement of outliers which may indicate that only a couple observations are responsible for multiple dependent variable outliers versus multiple observations having only one dependent variable outlier each. 

## Potential predictors of the dependent variable
To determine good potential predictors of the dependent variable, I look for independent variables that have a strong correlation (whether positive or negative) with the dependent variable. In this case, by plotting the scatter plots in the outlier section, I can also examine them to see if there are strong relationships present. That is, as SalePrice goes up, does the independent variable go up as well? Or as the SalePrice goes down, does the independent variable go down as well? Looking through the scatter plots, I find that TotalBsmtSF, GrLivArea, FullBath, GarageArea, GarageYrBlt, TotRmsAbvGrd, 1stflrSF, YearBuilt, and YearRemodAdd all visually present strong correlations with SalePrice. I then subset to these variables plus SalePrice and create a correlation matrix. 

Determining the best three potential predictors is not as simple as selecting the top three indepenent variables based upon their correlation values with SalePrice. Independent variables can be highly correlated among themselves and thus are likely explaining the same type of variation found in the dependent variable. For example, we find the GrLivArea, GarageArea, and 1stFlrSF have the highest correlations with SalePrice. However, GrLivArea and 1stFlrSF are correlated (.57) and the next variable in order of highest correlation of SalePrice is FullBath but I also don't choose that independent variable since it has a correlation of .63 with GrLivArea. Instead, I choose YearBuilt as the last best potential predictor since it is next on the list of correlation with SalePrice and is not correlated with GrLivArea (.2) meaning it is explaining different variation in the dependent variable. 

## Feature creation
Domain knowledge can be an asset when conducting feature creation. In this case, most home buyers think of baths as a single variable. For example, a house with 3 and a half baths is throught of as 3.5 baths total, not 1 full bath in the basement, 1 full bath on the first floor, half bath on the first floor, and full bath on the second floor. I create a new variable, Baths, which is a sum of the four bath variables in the dataset. I then run a correlation matrix of SalePrice, Baths, and the four variables that consist of Bath. I find that Baths has a correlation of .61 with SalePrice, which is better than any of the four variables on their own.

I additionally create a variable called TotSF (total square feet). The dataset has the house square footage broken into three variables, basement, living area (above grade), and garage area. By combining these three variables into TotSF and running a correlation matrix, I find TotSF has a correlation of .81 with SalePrice which is better than any of the three variables on their own. 

## Min-max and standard scaling
In order to perform min-max and standard scaling, we first must drop the variable Id. This is just an Id column and provides no information about the observation. Additionally, including it in scaling can cause issues due to its large range and values. Second, in order to perform valid scaling, we must get rid of categorical variables and instead replace them with dummy variables. Dummy variables are derivied from a variable with categorical values and each new dummy variable represents a value found in the original variable. Thus, the values the dummy variable can take on are either 1 or 0 for each observation. 
